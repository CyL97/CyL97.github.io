<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="css/css.css">
  <title>Document</title>
</head>

<body>

  <div class="header">
    <div class="nav">
      <ul>
        <li><a href="index.html">About</a> </li>
        <li><a href="Publications.html">Publications</a> </li>
        <li><a href="./CV.pdf">CV</a> </li>
      </ul>
      <div class="menu">

      </div>

    </div>
  </div>
  <div class="main">


 
 
  
   
    <div class="tits">
        Publications

    </div>
    <div class="year">
      2026
    </div>
    <div class="selectlist">
        <dl>
          <dt>
             <img src="./images/img8.png" alt="">
          </dt>
          <dd>
            <h3>CASHEW: Stabilizing Multimodal Reasoning via Iterative Trajectory Aggregation</h3>
            <p>Chaoyu Li, Deeparghya Dutta Barua, Fei Tao, Pooyan Fazli </p>
            <h4>
              <a href="">arXiv</a>
            </h4>
          </dd>
        </dl>
    </div>
    <div class="year">
      2025
    </div>
    <div class="selectlist">
        <dl>
          <dt>
             <img src="./images/img7.png" alt="">
          </dt>
          <dd>
            <h3>FrameOracle: Learning What to See and How Much to See in Videos</h3>
            <p>Chaoyu Li, Tianzhi Li, Fei Tao, Zhenyu Zhao, Ziqian Wu, Maozheng Zhao, </p>
            <p>Juntong Song, Cheng Niu, Pooyan Fazli </p>
            <h4>
              <a href="https://arxiv.org/abs/2510.03584">arXiv</a>
            </h4>
          </dd>
        </dl>
        <dl>
          <dt>
             <img src="./images/img6.png" alt="">
          </dt>
          <dd>
            <h3>ReGATE: Learning Faster and Better with Fewer Tokens in MLLMs</h3>
            <p>Chaoyu Li, Yogesh Kulkarni, Pooyan Fazli </p>
            <h4>
              <a href="https://arxiv.org/abs/2507.21420">arXiv</a>
            </h4>
          </dd>
        </dl>
        <dl>
          <dt>
             <img src="./images/img4.png" alt="">
          </dt>
          <dd>
            <h3>VidHalluc: Evaluating Temporal Hallucinations in Multimodal Large Language Models<br> 
              for Video Understanding</h3>
            <p>Chaoyu Li, Eun Woo Im, Pooyan Fazli </p>
            <p> <i>  The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),</i> 2025</p>
            <h4>
              <a href="https://www.arxiv.org/abs/2412.03735">arXiv</a>
              <a href="https://vid-halluc.github.io/">Project</a>
            </h4>
          </dd>
        </dl>

        <dl>
          <dt>
             <img src="./images/img5.png" alt="">
          </dt>
          <dd>
            <h3>VideoA11y: Method and Dataset for Accessible Video Description</h3>
            <p>Chaoyu Li, Sid Padmanabhuni, Maryam S Cheema, Hasti Seifi, Pooyan Fazli </p>
            <p> <i>  ACM SIGCHI Conference on Human Factors in Computing Systems (CHI) ,</i> 2025</p>
            <h4>
              <a href="https://arxiv.org/abs/2502.20480">arXiv</a>
              <a href="https://people-robots.github.io/VideoA11y/">Project</a>
            </h4>
          </dd>
        </dl>
    </div>
    <div class="year">
      2021
    </div>
    <div class="selectlist">
        <dl>
          <dt>
             <img src="./images/img1.png" alt="">
          </dt>
          <dd>
            <h3> Infrared Action Detection in the Dark via Cross-Stream Attention Mechanism </h3>
            <p> Xu Chen*, Chenqiang Gao*, Chaoyu Li, Yi Yang, Deyu Meng </p>
            <p> <i>  IEEE Transactions on Multimedia(TMM) ,</i> 2021</p>
            <h4><a href="./Infrared Action Detection in the Dark via Cross-Stream Attention Mechanism.pdf">PDF</a></h4>
          </dd>
        </dl>
      </div>
      <div class="year">
        2019
      </div>
      <div class="selectlist"> 
        <dl>
          <dt>
             <img src="./images/img2.png" alt="">
          </dt>
          <dd>
            <h3>  NTT CQUPT@TRECVID2019 ActEV: Activities in Extended Video  </h3>
            <p> Yongqing Sun, Xu Chen, Chaoyu Li et al.  </p>
            <p> <i> TREC Video Retrieval Evaluation (TRECVID), </i> 2019</p>
            <h4><a href="./ntt_cqupt.pdf">PDF</a></h4>
          </dd>
        </dl>
        <dl>
          <dt>
             <img src="./images/img3.png" alt="">
          </dt>
          <dd>
            <h3> Face Anti-Spoofing Based on Multi-layer Domain Adaptation </h3>
            <p> Fengshun Zhou*, Chenqiang Gao*, Fang Chen, Chaoyu Li, Xindou Li, Feng Yang, Yue Zhao </p>
            <p> <i> IEEE International Conference on Multimedia & Expo Workshops (ICMEW) , </i> 2019</p>
            <h4><a href="./FACE ANTI-SPOOFING BASED ON MULTI-LAYER DOMAIN ADAPTATION.pdf">PDF</a></h4>
          </dd>
        </dl>
    </div>
   
   
  </div>

  <div class="footer">
      <div class="footbox">
        © Copyright 2025 Chaoyu Li. Last updated: December 29, 2024.
      </div>
  </div>
  <script src="./js/jquery.min.js"></script>
  <script src="./js/js.js"></script>
</body>

</html>




